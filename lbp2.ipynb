{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a0f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-image\n",
    "%pip install numpy opencv-python scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964210d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import canberra\n",
    "\n",
    "class CBIRSystem:\n",
    "    def __init__(self, database_path, patch_size=128, n_color_clusters=64):\n",
    "        \"\"\"\n",
    "        Inisialisasi sistem CBIR\n",
    "        \n",
    "        Parameters:\n",
    "            database_path (str): Path ke folder database Brodatz\n",
    "            patch_size (int): Ukuran potongan citra (default: 128)\n",
    "            n_color_clusters (int): Jumlah cluster untuk kuantisasi warna (default: 64)\n",
    "        \"\"\"\n",
    "        self.database_path = database_path\n",
    "        self.patch_size = patch_size\n",
    "        self.n_color_clusters = n_color_clusters\n",
    "        self.image_descriptors = []\n",
    "        self.image_patches = []\n",
    "        self.class_labels = []\n",
    "        self.patch_indices = []  # Untuk tracking patch dari citra mana\n",
    "        self.kmeans_color = None\n",
    "        self.feature_scaler = None\n",
    "        self.nn_model = None\n",
    "        \n",
    "    def load_and_preprocess_images(self):\n",
    "        \"\"\"Memuat dan memproses citra dari database\"\"\"\n",
    "        print(\"Memuat dan memproses citra dari database...\")\n",
    "        \n",
    "        # Daftar semua file citra dalam format D{nomor}_COLORED.tif\n",
    "        image_files = sorted([f for f in os.listdir(self.database_path) \n",
    "                           if f.endswith('_COLORED.tif') and f.startswith('D')])\n",
    "        \n",
    "        # Kumpulkan semua pixel untuk training K-Means\n",
    "        all_pixels = []\n",
    "        \n",
    "        for class_idx, img_file in enumerate(image_files):\n",
    "            img_path = os.path.join(self.database_path, img_file)\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"Gagal memuat citra: {img_file}\")\n",
    "                continue\n",
    "                \n",
    "            # Resize citra jika diperlukan\n",
    "            if img.shape[0] != 640 or img.shape[1] != 640:\n",
    "                img = cv2.resize(img, (640, 640))\n",
    "                \n",
    "            # Split citra menjadi 25 patch (5x5 grid)\n",
    "            for i in range(5):\n",
    "                for j in range(5):\n",
    "                    y_start = i * self.patch_size\n",
    "                    y_end = y_start + self.patch_size\n",
    "                    x_start = j * self.patch_size\n",
    "                    x_end = x_start + self.patch_size\n",
    "                    \n",
    "                    patch = img[y_start:y_end, x_start:x_end]\n",
    "                    self.image_patches.append(patch)\n",
    "                    self.class_labels.append(class_idx)\n",
    "                    self.patch_indices.append((class_idx, i, j))\n",
    "                    \n",
    "                    # Kumpulkan pixel untuk training K-Means\n",
    "                    pixels = patch.reshape(-1, 3).astype(np.float32)\n",
    "                    sample_size = min(1000, len(pixels))  # Ambil sampel dari setiap patch\n",
    "                    sample_indices = np.random.choice(len(pixels), sample_size, replace=False)\n",
    "                    all_pixels.extend(pixels[sample_indices])\n",
    "        \n",
    "        # Training K-Means dengan pixel dari semua patch\n",
    "        print(\"Training K-Means untuk kuantisasi warna...\")\n",
    "        all_pixels = np.array(all_pixels)\n",
    "        sample_size = min(100000, len(all_pixels))\n",
    "        sample_indices = np.random.choice(len(all_pixels), sample_size, replace=False)\n",
    "        sample_pixels = all_pixels[sample_indices]\n",
    "        \n",
    "        self.kmeans_color = KMeans(n_clusters=self.n_color_clusters, random_state=42, n_init=10)\n",
    "        self.kmeans_color.fit(sample_pixels)\n",
    "        \n",
    "        # Ekstrak fitur dari semua patch\n",
    "        print(\"Ekstraksi fitur dari semua patch...\")\n",
    "        for patch in self.image_patches:\n",
    "            features = self.extract_features(patch)\n",
    "            self.image_descriptors.append(features)\n",
    "                    \n",
    "        self.image_descriptors = np.array(self.image_descriptors)\n",
    "        self.class_labels = np.array(self.class_labels)\n",
    "        print(f\"Berhasil memuat {len(self.image_patches)} patch citra dari {len(image_files)} kelas.\")\n",
    "        \n",
    "    def extract_features(self, image):\n",
    "        \"\"\"Mengekstrak fitur LBP dan warna dari citra\"\"\"\n",
    "        # Konversi ke grayscale untuk LBP\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 1. Ekstrak fitur LBP dengan parameter yang lebih baik\n",
    "        radius = 2\n",
    "        n_points = 8 * radius\n",
    "        lbp = local_binary_pattern(gray, n_points, radius, method='uniform')\n",
    "        \n",
    "        # Hitung histogram LBP\n",
    "        n_bins = n_points + 2  # uniform bins + non-uniform bin\n",
    "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))\n",
    "        lbp_hist = lbp_hist.astype(float)\n",
    "        lbp_hist /= (lbp_hist.sum() + 1e-8)  # Normalisasi dengan epsilon untuk stabilitas\n",
    "        \n",
    "        # 2. Hitung Maximum Run Length dari LBP\n",
    "        max_run_length = self.calculate_max_run_length(lbp)\n",
    "        \n",
    "        # 3. Ekstrak fitur warna menggunakan K-Means\n",
    "        color_features = self.extract_color_features(image)\n",
    "        \n",
    "        # 4. Ekstrak fitur statistik tambahan\n",
    "        mean_colors = np.mean(image.reshape(-1, 3), axis=0)\n",
    "        std_colors = np.std(image.reshape(-1, 3), axis=0)\n",
    "        \n",
    "        # Gabungkan semua fitur\n",
    "        features = np.concatenate([\n",
    "            lbp_hist,               # Histogram LBP\n",
    "            [max_run_length],       # Maximum run length\n",
    "            color_features,         # Histogram warna (K-Means)\n",
    "            mean_colors,            # Rata-rata warna\n",
    "            std_colors              # Standar deviasi warna\n",
    "        ])\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    def calculate_max_run_length(self, lbp_image):\n",
    "        \"\"\"Menghitung maximum run length dari citra LBP\"\"\"\n",
    "        max_run = 0\n",
    "        rows, cols = lbp_image.shape\n",
    "        \n",
    "        # Periksa arah horizontal\n",
    "        for i in range(rows):\n",
    "            current_val = lbp_image[i, 0]\n",
    "            current_run = 1\n",
    "            \n",
    "            for j in range(1, cols):\n",
    "                if lbp_image[i, j] == current_val:\n",
    "                    current_run += 1\n",
    "                else:\n",
    "                    max_run = max(max_run, current_run)\n",
    "                    current_val = lbp_image[i, j]\n",
    "                    current_run = 1\n",
    "            max_run = max(max_run, current_run)\n",
    "                    \n",
    "        # Periksa arah vertikal\n",
    "        for j in range(cols):\n",
    "            current_val = lbp_image[0, j]\n",
    "            current_run = 1\n",
    "            \n",
    "            for i in range(1, rows):\n",
    "                if lbp_image[i, j] == current_val:\n",
    "                    current_run += 1\n",
    "                else:\n",
    "                    max_run = max(max_run, current_run)\n",
    "                    current_val = lbp_image[i, j]\n",
    "                    current_run = 1\n",
    "            max_run = max(max_run, current_run)\n",
    "                    \n",
    "        return max_run\n",
    "        \n",
    "    def extract_color_features(self, image):\n",
    "        \"\"\"Mengekstrak fitur warna menggunakan K-Means\"\"\"\n",
    "        # Ubah bentuk citra menjadi array pixel\n",
    "        pixels = image.reshape(-1, 3).astype(np.float32)\n",
    "        \n",
    "        # Prediksi cluster untuk semua pixel\n",
    "        clusters = self.kmeans_color.predict(pixels)\n",
    "        \n",
    "        # Buat histogram warna\n",
    "        hist, _ = np.histogram(clusters, bins=self.n_color_clusters, range=(0, self.n_color_clusters-1))\n",
    "        hist = hist.astype(float)\n",
    "        hist /= (hist.sum() + 1e-8)  # Normalisasi dengan epsilon\n",
    "        \n",
    "        return hist\n",
    "        \n",
    "    def modified_canberra_distance(self, x, y):\n",
    "        \"\"\"Implementasi jarak Canberra yang dimodifikasi\"\"\"\n",
    "        numerator = np.abs(x - y)\n",
    "        denominator = np.abs(x) + np.abs(y) + 1e-8  # Tambahkan epsilon untuk stabilitas\n",
    "        return np.sum(numerator / denominator)\n",
    "        \n",
    "    def train_model(self, distance_metric='canberra'):\n",
    "        \"\"\"Melatih model untuk pencarian citra\"\"\"\n",
    "        print(\"Melatih model CBIR...\")\n",
    "        \n",
    "        # Standarisasi fitur\n",
    "        self.feature_scaler = StandardScaler()\n",
    "        scaled_features = self.feature_scaler.fit_transform(self.image_descriptors)\n",
    "        \n",
    "        # Buat model Nearest Neighbors\n",
    "        if distance_metric == 'canberra':\n",
    "            self.nn_model = NearestNeighbors(n_neighbors=50, metric='canberra')\n",
    "        elif distance_metric == 'euclidean':\n",
    "            self.nn_model = NearestNeighbors(n_neighbors=50, metric='euclidean')\n",
    "        else:  # manhattan\n",
    "            self.nn_model = NearestNeighbors(n_neighbors=50, metric='manhattan')\n",
    "            \n",
    "        self.nn_model.fit(scaled_features)\n",
    "        print(f\"Model berhasil dilatih menggunakan metric: {distance_metric}\")\n",
    "        \n",
    "    def query_image(self, query_image_path, k=10):\n",
    "        \"\"\"Mencari citra yang mirip dengan citra query\"\"\"\n",
    "        query_img = cv2.imread(query_image_path)\n",
    "        if query_img is None:\n",
    "            print(\"Error: Gagal memuat citra query\")\n",
    "            return []\n",
    "            \n",
    "        # Resize citra query jika diperlukan\n",
    "        if query_img.shape[0] != self.patch_size or query_img.shape[1] != self.patch_size:\n",
    "            query_img = cv2.resize(query_img, (self.patch_size, self.patch_size))\n",
    "            \n",
    "        # Ekstrak fitur\n",
    "        query_features = self.extract_features(query_img)\n",
    "        scaled_features = self.feature_scaler.transform([query_features])\n",
    "        \n",
    "        # Cari citra yang mirip\n",
    "        distances, indices = self.nn_model.kneighbors(scaled_features, n_neighbors=k)\n",
    "        \n",
    "        # Kembalikan hasil\n",
    "        results = []\n",
    "        for i, dist in zip(indices[0], distances[0]):\n",
    "            results.append({\n",
    "                'patch': self.image_patches[i],\n",
    "                'distance': dist,\n",
    "                'class': self.class_labels[i]\n",
    "            })\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    def evaluate_retrieval(self, test_size=0.3, k_values=[5, 10, 15, 20]):\n",
    "        \"\"\"Evaluasi performa sistem dengan precision dan recall untuk berbagai k\"\"\"\n",
    "        print(\"Evaluasi performa sistem...\")\n",
    "        \n",
    "        # Gunakan stratified sampling untuk memastikan setiap kelas terwakili\n",
    "        # Pilih beberapa patch dari setiap kelas untuk testing\n",
    "        unique_classes = np.unique(self.class_labels)\n",
    "        test_indices = []\n",
    "        train_indices = []\n",
    "        \n",
    "        for class_id in unique_classes:\n",
    "            class_indices = np.where(self.class_labels == class_id)[0]\n",
    "            n_test = max(1, int(len(class_indices) * test_size))  # Minimal 1 sample per kelas\n",
    "            \n",
    "            test_class_indices = np.random.choice(class_indices, size=n_test, replace=False)\n",
    "            train_class_indices = np.setdiff1d(class_indices, test_class_indices)\n",
    "            \n",
    "            test_indices.extend(test_class_indices)\n",
    "            train_indices.extend(train_class_indices)\n",
    "        \n",
    "        test_indices = np.array(test_indices)\n",
    "        train_indices = np.array(train_indices)\n",
    "        \n",
    "        # Standarisasi fitur\n",
    "        scaled_features = self.feature_scaler.transform(self.image_descriptors)\n",
    "        \n",
    "        # Buat model evaluasi\n",
    "        max_k = min(max(k_values), len(train_indices))\n",
    "        eval_model = NearestNeighbors(n_neighbors=max_k, metric='canberra')\n",
    "        eval_model.fit(scaled_features[train_indices])\n",
    "        \n",
    "        results = {}\n",
    "        \n",
    "        for k in k_values:\n",
    "            if k > len(train_indices):\n",
    "                print(f\"Skipping k={k} karena lebih besar dari jumlah data training\")\n",
    "                continue\n",
    "                \n",
    "            precisions = []\n",
    "            recalls = []\n",
    "            \n",
    "            for test_idx in test_indices:\n",
    "                true_label = self.class_labels[test_idx]\n",
    "                \n",
    "                # Cari neighbors\n",
    "                _, neighbor_indices = eval_model.kneighbors([scaled_features[test_idx]], n_neighbors=k)\n",
    "                \n",
    "                # Get actual neighbor labels from training set\n",
    "                actual_neighbor_indices = train_indices[neighbor_indices[0]]\n",
    "                neighbor_labels = self.class_labels[actual_neighbor_indices]\n",
    "                \n",
    "                # Hitung precision dan recall\n",
    "                relevant_retrieved = np.sum(neighbor_labels == true_label)\n",
    "                precision = relevant_retrieved / k\n",
    "                \n",
    "                # Hitung recall\n",
    "                total_relevant_in_train = np.sum(self.class_labels[train_indices] == true_label)\n",
    "                recall = relevant_retrieved / total_relevant_in_train if total_relevant_in_train > 0 else 0\n",
    "                \n",
    "                precisions.append(precision)\n",
    "                recalls.append(recall)\n",
    "                \n",
    "            avg_precision = np.mean(precisions)\n",
    "            avg_recall = np.mean(recalls)\n",
    "            f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "            \n",
    "            results[k] = {\n",
    "                'precision': avg_precision,\n",
    "                'recall': avg_recall,\n",
    "                'f1_score': f1_score\n",
    "            }\n",
    "            \n",
    "            print(f\"Hasil evaluasi (k={k}):\")\n",
    "            print(f\"  Rata-rata Precision: {avg_precision:.4f}\")\n",
    "            print(f\"  Rata-rata Recall:    {avg_recall:.4f}\")\n",
    "            print(f\"  F1-Score:           {f1_score:.4f}\")\n",
    "            print(f\"  Jumlah data test:    {len(test_indices)}\")\n",
    "            print(f\"  Jumlah data train:   {len(train_indices)}\")\n",
    "            print()\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    def evaluate_by_same_image(self, k=10):\n",
    "        \"\"\"Evaluasi dengan menggunakan patch dari citra yang sama sebagai ground truth\"\"\"\n",
    "        print(\"Evaluasi berdasarkan patch dari citra yang sama...\")\n",
    "        \n",
    "        # Pilih beberapa patch secara acak untuk evaluasi\n",
    "        test_indices = np.random.choice(len(self.image_patches), size=200, replace=False)\n",
    "        \n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        \n",
    "        scaled_features = self.feature_scaler.transform(self.image_descriptors)\n",
    "        eval_model = NearestNeighbors(n_neighbors=k+1, metric='canberra')  # +1 karena akan mengabaikan diri sendiri\n",
    "        eval_model.fit(scaled_features)\n",
    "        \n",
    "        for test_idx in test_indices:\n",
    "            true_class = self.class_labels[test_idx]\n",
    "            \n",
    "            # Cari neighbors (termasuk diri sendiri)\n",
    "            _, neighbor_indices = eval_model.kneighbors([scaled_features[test_idx]], n_neighbors=k+1)\n",
    "            \n",
    "            # Hapus diri sendiri dari hasil\n",
    "            neighbor_indices = neighbor_indices[0][1:]  # Skip index pertama (diri sendiri)\n",
    "            neighbor_labels = self.class_labels[neighbor_indices]\n",
    "            \n",
    "            # Hitung precision dan recall\n",
    "            relevant_retrieved = np.sum(neighbor_labels == true_class)\n",
    "            precision = relevant_retrieved / k\n",
    "            \n",
    "            # Total patch dari kelas yang sama (minus diri sendiri)\n",
    "            total_relevant = np.sum(self.class_labels == true_class) - 1\n",
    "            recall = relevant_retrieved / min(total_relevant, k) if total_relevant > 0 else 0\n",
    "            \n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "        \n",
    "        avg_precision = np.mean(precisions)\n",
    "        avg_recall = np.mean(recalls)\n",
    "        f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "        \n",
    "        print(f\"Evaluasi patch dari citra yang sama (k={k}):\")\n",
    "        print(f\"  Rata-rata Precision: {avg_precision:.4f}\")\n",
    "        print(f\"  Rata-rata Recall:    {avg_recall:.4f}\")\n",
    "        print(f\"  F1-Score:           {f1_score:.4f}\")\n",
    "        \n",
    "        return avg_precision, avg_recall, f1_score\n",
    "    \n",
    "    def simple_evaluation(self, k=10, n_samples=100):\n",
    "        \"\"\"Evaluasi sederhana untuk verifikasi sistem\"\"\"\n",
    "        print(f\"Evaluasi sederhana dengan {n_samples} sampel...\")\n",
    "        \n",
    "        # Pilih sampel secara acak\n",
    "        sample_indices = np.random.choice(len(self.image_patches), size=n_samples, replace=False)\n",
    "        \n",
    "        scaled_features = self.feature_scaler.transform(self.image_descriptors)\n",
    "        eval_model = NearestNeighbors(n_neighbors=k+1, metric='canberra')\n",
    "        eval_model.fit(scaled_features)\n",
    "        \n",
    "        precisions = []\n",
    "        \n",
    "        for sample_idx in sample_indices:\n",
    "            true_class = self.class_labels[sample_idx]\n",
    "            \n",
    "            # Cari neighbors (termasuk diri sendiri)\n",
    "            _, neighbor_indices = eval_model.kneighbors([scaled_features[sample_idx]], n_neighbors=k+1)\n",
    "            \n",
    "            # Hapus diri sendiri dari hasil\n",
    "            neighbor_indices = neighbor_indices[0][1:]  # Skip index pertama (diri sendiri)\n",
    "            neighbor_labels = self.class_labels[neighbor_indices]\n",
    "            \n",
    "            # Hitung precision\n",
    "            relevant_retrieved = np.sum(neighbor_labels == true_class)\n",
    "            precision = relevant_retrieved / k\n",
    "            precisions.append(precision)\n",
    "        \n",
    "        avg_precision = np.mean(precisions)\n",
    "        print(f\"Rata-rata Precision (evaluasi sederhana): {avg_precision:.4f}\")\n",
    "        \n",
    "        # Tampilkan distribusi precision\n",
    "        precision_dist = np.bincount([int(p*k) for p in precisions], minlength=k+1)\n",
    "        for i, count in enumerate(precision_dist):\n",
    "            if count > 0:\n",
    "                print(f\"  {i}/{k} relevan: {count} sampel ({count/n_samples*100:.1f}%)\")\n",
    "        \n",
    "        return avg_precision\n",
    "        \n",
    "    def visualize_results(self, query_image_path, results):\n",
    "        \"\"\"Visualisasi hasil pencarian\"\"\"\n",
    "        query_img = cv2.cvtColor(cv2.imread(query_image_path), cv2.COLOR_BGR2RGB)\n",
    "        if query_img.shape[0] != self.patch_size or query_img.shape[1] != self.patch_size:\n",
    "            query_img = cv2.resize(query_img, (self.patch_size, self.patch_size))\n",
    "        \n",
    "        n_results = min(10, len(results))\n",
    "        plt.figure(figsize=(18, 4))\n",
    "        plt.suptitle(\"Hasil Pencarian Citra Berbasis Konten\", fontsize=16)\n",
    "        \n",
    "        # Tampilkan citra query\n",
    "        plt.subplot(1, n_results+1, 1)\n",
    "        plt.imshow(query_img)\n",
    "        plt.title(\"Citra Query\", fontsize=12, fontweight='bold')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Tampilkan hasil\n",
    "        for i, result in enumerate(results[:n_results]):\n",
    "            plt.subplot(1, n_results+1, i+2)\n",
    "            img = cv2.cvtColor(result['patch'], cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(img)\n",
    "            plt.title(f\"Class: {result['class']}\\nDist: {result['distance']:.3f}\", fontsize=10)\n",
    "            plt.axis('off')\n",
    "            \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def analyze_feature_importance(self):\n",
    "        \"\"\"Analisis pentingnya fitur\"\"\"\n",
    "        features = self.image_descriptors\n",
    "        \n",
    "        # Hitung statistik fitur\n",
    "        feature_means = np.mean(features, axis=0)\n",
    "        feature_stds = np.std(features, axis=0)\n",
    "        \n",
    "        # Identifikasi komponen fitur\n",
    "        lbp_size = 18  # n_points + 2 untuk uniform LBP\n",
    "        run_length_size = 1\n",
    "        color_size = self.n_color_clusters\n",
    "        mean_color_size = 3\n",
    "        std_color_size = 3\n",
    "        \n",
    "        print(\"Analisis Fitur:\")\n",
    "        print(f\"- LBP Histogram: {lbp_size} fitur\")\n",
    "        print(f\"- Maximum Run Length: {run_length_size} fitur\")\n",
    "        print(f\"- Color Histogram: {color_size} fitur\")\n",
    "        print(f\"- Mean Colors: {mean_color_size} fitur\")\n",
    "        print(f\"- Std Colors: {std_color_size} fitur\")\n",
    "        print(f\"Total fitur: {len(feature_means)}\")\n",
    "\n",
    "# Contoh penggunaan yang diperbaiki\n",
    "if __name__ == \"__main__\":\n",
    "    # Inisialisasi sistem dengan parameter yang lebih baik\n",
    "    database_path = \"./Colored_Brodatz\"\n",
    "    cbir = CBIRSystem(database_path, n_color_clusters=64)  # Meningkatkan jumlah cluster warna\n",
    "    \n",
    "    # Memuat dan memproses citra\n",
    "    cbir.load_and_preprocess_images()\n",
    "    \n",
    "    # Analisis fitur\n",
    "    cbir.analyze_feature_importance()\n",
    "    \n",
    "    # Melatih model dengan jarak Canberra\n",
    "    cbir.train_model(distance_metric='canberra')\n",
    "    \n",
    "    # Evaluasi performa dengan berbagai k\n",
    "    results = cbir.evaluate_retrieval(test_size=0.3, k_values=[5, 10, 15, 20])\n",
    "    \n",
    "    # Evaluasi tambahan berdasarkan patch dari citra yang sama\n",
    "    cbir.evaluate_by_same_image(k=10)\n",
    "    \n",
    "    # Evaluasi sederhana untuk verifikasi\n",
    "    print(\"\\n=== Evaluasi Sederhana ===\")\n",
    "    cbir.simple_evaluation(k=10)\n",
    "    \n",
    "    # Contoh pencarian\n",
    "    query_path = \"./Colored_Brodatz/D27_COLORED.tif\"\n",
    "    if os.path.exists(query_path):\n",
    "        # Buat patch query (ambil patch tengah)\n",
    "        query_img = cv2.imread(query_path)\n",
    "        if query_img is not None:\n",
    "            query_img = cv2.resize(query_img, (640, 640))\n",
    "            # Ambil patch tengah (2,2)\n",
    "            patch = query_img[256:384, 256:384]  # Patch tengah dari grid 5x5\n",
    "            cv2.imwrite(\"query_patch.jpg\", patch)\n",
    "            \n",
    "            results = cbir.query_image(\"query_patch.jpg\", k=10)\n",
    "            cbir.visualize_results(\"query_patch.jpg\", results)\n",
    "    else:\n",
    "        print(f\"Citra query {query_path} tidak ditemukan\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
